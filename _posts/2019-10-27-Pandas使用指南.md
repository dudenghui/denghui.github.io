# Pandas使用指南

**Pandas** 是一个 [Python](https://www.python.org/) 的包，提供快速、灵活和富有表现力的数据结构，旨在使“关系”或“标记”数据的使用既简单又直观。它的目标是成为用Python进行实际的、**真实**的数据分析的基础高级模块。此外，**它还有更宏远的目标，即成为超过任何语言的最强大，最灵活的开源数据分析/操作工具**。它已朝着这个目标迈进。

pandas 非常适合许多不同类型的数据：

- 具有异构类型列的表格数据，如SQL表或Excel电子表格。
- 有序和无序（不一定是固定频率）时间序列数据。
- 具有行和列标签的任意矩阵数据（均匀类型或异构）。
- 任何其他形式的观察/统计数据集。 实际上不需要将数据标记为放置在Pandas数据结构中。

pandas 的两个主要数据结构，[Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series)（1维）和[DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame)（2维），处理金融，统计，社会科学和许多工程领域中的绝大多数典型用例。 对于R用户，DataFrame提供R的data.frame提供的所有内容以及更多内容。pandas 建立在[NumPy](https://www.numpy.org/)之上，旨在与许多其他第三方库完美地集成在科学计算环境中。

以下是 pandas 做够胜任的一些事情：

- 在浮点和非浮点数据中轻松处理**缺失数据**（表示为NaN）。
- 大小可变性：可以从DataFrame和更高维度的对象中**插入和删除**。
- 自动和显式**数据对齐**：对象可以明确地与一组标签对齐，或者用户可以简单地忽略标签，让Series，DataFrame等在计算中自动对齐数据
- 强大，灵活的**组（group by）**功能，可对数据集执行拆分应用组合操作，用于聚合和转换数据。
- **轻松**将其他Python和NumPy数据结构中的不规则，不同索引数据转换为DataFrame对象。
- 基于智能标签的**切片**，**花式索引**和**子集**大数据集。
- 直观**合并**和**加入**数据集。
- 灵活的**重塑**和数据集的旋转。
- **轴的分层**标记（每个刻度可能有多个标签）。
- 强大的IO工具，用于从**平面文件**（CSV和分隔）、Excel文件、数据库以及能从超快的**HDF5格式**中保存或加载数据。
- **特定时间序列**功能：日期范围生成和频率转换、移动窗口统计、移动窗口线性回归、日期转换和滞后等。

其中许多技术都是为了解决使用其他语言/科研环境时经常遇到的缺点。对于数据科学家来说，处理数据通常分为多个阶段：整理和清理数据，分析/建模数据，然后将分析结果组织成适合绘图或表格显示的形式。Pandas 是完成所有这些任务的理想工具。

其他一些说明

- pandas 的开发速度**很快**。许多低级算法位已经在[Cython](https://cython.org/)代码中进行了大量优化。然而，与其他任何事物一样，这样做通常会牺牲性能。 因此，如果您专注于应用程序的一个功能，您可以更快创建一个专用的工具。
- pandas 是[statsmodels](https://www.statsmodels.org/stable/index.html)的依赖，使其成为Python中统计计算生态系统的重要组成部分。
- pandas 已广泛用于金融领域的应用和生产。

## 数据结构

| 维数 | 名称      | 描述                                                         |
| ---- | --------- | ------------------------------------------------------------ |
| 1    | Series    | 可以看做有标签（默认是整数序列RangeIndex；可以重复）的一维数组（同类型）。是scalars的集合，同时也是DataFrame的元素。 |
| 2    | DataFrame | 一般是二维标签，尺寸可变的表格结构，具有潜在的异质型列。     |

### 为什么有多个数据结构？

考虑 pandas 数据结构的最佳方式是作为低维数据的灵活容器。例如，DataFrame是Series的容器，Series是scalars的容器。我们希望能够以类似字典的方式从这些容器中插入和删除对象。

此外，我们希望通用API函数的合理默认行为考虑到时间序列和横截面数据集的典型方向。当使用ndarrays存储2维和3维数据时，在编写函数时会给用户带来负担以考虑数据集的方向; 轴被认为或多或少相等（除非C-或Fortran-连续性对性能有影响）。在Pandas中，轴旨在为数据提供更多的语义含义; 即，对于特定数据集，可能存在定向数据的“正确”方式。因此，目标是减少在下游功能中编码数据转换所需的精力。

此外，我们希望公共API函数的合理默认行为考虑到时间序列和横截面数据集的典型方向。当使用ndarray存储2维和3维数据时，用户在编写函数时需要考虑数据集的方向；轴被认为或多或少是等价的(除非C或Fortran邻接关系到性能)。在Pandas中，轴旨在为数据提供更多的语义含义；即，对于特定的数据集，可能会有一种“正确”的方式来确定数据的方向。因此，目标是减少在下游函数中编写数据转换代码所需的脑力劳动。

举个例子，对于表格数据(DataFrame)，考虑***索引**(行)和**列**(而不是轴0和轴1)在语义上更有帮助。因此，迭代DataFrame的列会产生更具可读性的代码：

```python
for col in df.columns:
    series = df[col]
    # do something with series
```

## 常用操作
<font color=red>使用pandas几乎就是在使用Series和DataFraame两个数据结构，将数据储存在这两个数据结构中，从而进行一系列操作</font>

series = 索引+1列   dataFrame = 索引+n列

常用的操作包括：

### 创建数据

#### 直接创建 

```python
s = pd.Series([1, 3, 5, np.nan, 6, 8])
s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20130102', periods=6))
dates = pd.date_range('20130101', periods=6)
df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))
#list('ABCD')为'A' 'B' 'C' 'D'
df2 = pd.DataFrame({
    		'A': 1.,
            'B': pd.Timestamp('20130102'),
            'C': pd.Series(1, index=list(range(4)), dtype='float32'),
            'D': np.array([3] * 4, dtype='int32'),
            'E': pd.Categorical(["test", "train", "test", "train"]),
            'F': 'foo'}) 
df3 = pd.DataFrame(
    		[[4, 7, 10],
			[5, 8, 11],
			[6, 9, 12]],
			index=[1, 2, 3],
			columns=['a', 'b', 'c'])
df4 = pd.DataFrame(                #Create DataFrame with a MultiIndex
			{"a" : [4 ,5, 6],
			"b" : [7, 8, 9],
			"c" : [10, 11, 12]},
			index = pd.MultiIndex.from_tuples([('d',1),('d',2),('e',2)],names=['n','v'])) 
```

#### 导入数据

#### 与numpy/Python进行转换

> DataFrame.to_numpy() 会给出一个比较底层的NumPy对象。
>
> 注意，当你的 DataFrame 有多个列并且每列的数据类型不同时，这个操作是不可行的，这也可以说是Pandas和NumPy之间的根本区别：NumPy的每一个array对象只有一种数据类型，但是Pandas的每一列的数据类型都是相同的（译者注：Pandas不需要像Numpy那样所有元素的类型都相同）. 当你调用 DataFrame.to_numpy()时, Pandas会寻找可以涵盖DataFrame中所有元素类型的NumPy数据类型。 这可能最终成为对象，需要将每个值强制转换为Python对象。

```python
df.to_numpy()#必须是df(pandas数据类型)的所有数据类型一样时才能进行，转化为多维numpy数组
```



#### series与dataFrame进行转换

### 查询数据

#### 切片数据

```python
df['A']#选择一个列，产生一个“Series”，相当于“df.A”
df[0:3]#对数据进行切片0-2行  默认行

#按标签索引
df.loc[dates[0]]#通过标签获取一行数据
df.loc[:,['A', 'B']]#通过标签在多个轴上选择数据
df.loc['20130102':'20130104', ['A', 'B']]#通过标签同时在两个轴上切片
df.loc[dates[0], 'A']#获取标量值   或者
df.at[dates[0], 'A']

#按位置选择
df.iloc[3]#第四行
df.iloc[3:5, 0:2]#进行切片 类似于原生切片
df.iloc[[1, 2, 4], [0, 2]]#
df.iloc[1:3, :]
df.iloc[1, 1]#获取单个数值

#布尔索引
df[df.A > 0]#选取A中数据大于0的行
df[df > 0]#从满足布尔条件的DataFrame中选择值

#按照特定值进行过滤
#使用 isin() 方法过滤：
df2 = df.copy()
df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']
df2[df2['E'].isin(['two', 'four'])]#获取E列中存在'two', 'four'的行

```

#### 头部、尾部、描述性统计

```python
df.head()#默认前5个
df.tail(3)#最后3个
df.describe()#显示数据的快速统计摘要
df.index#显示索引（行）
df.columns#显示列
```

### 处理数据

#### 添加、删除

```python
df.append(s, ignore_index=True)#默认为行拼接 忽视索引添加新的索引
```



#### 展开

```python
pd.melt(df)#按列重新展开成一个新的列
dff.pivot(columns='variable', values='value')#相当于上一个的逆过程

```



#### 拼接

```python
dff = pd.DataFrame(
            {"a":[4,5,6],
             "b":[5,6,7],   
             "c":[6,7,8]},
            index = [1,2,3])

dff1 = pd.DataFrame(
            {"a":[4,5,6],
             "b":[5,6,7],   
             "c":[6,7,8]},
            index = [4,5,6])
pd.concat([dff1,dff])#上下相接 column必须相同

dff2 = pd.DataFrame(
            {"d":[4,5,6],
             "e":[5,6,7],   
             "f":[6,7,8]},
            index = [1,2,3])
pd.concat([dff2,dff],axis=1)#左右相接 index必须相同
```

```python
#拆完重新拼接
pieces = [df[:3], df[3:7], df[7:]]
pd.concat(pieces)
```

#### 融合

```python
left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})
right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})
pd.merge(left, right, on='key')#key相同，两两互相
```

```python
left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})
right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})
pd.merge(left, right, on='key')#注意与上边区别
```



#### 修改

* 直接按照查询数据的方法赋予指定大小与形状的数据
* 一些特殊的用法

```python
df2 = df.copy()
df2[df2 > 0] = -df2#带条件的赋值
```



#### 排序

```python
df.sort_index(axis=1, ascending=False)
#按轴排序（即按照横轴与纵轴的索引来排序）  
#axis=0代表纵的索引，axis=1代表横的索引；
#ascending=False代表将列按照逆序排列，否则按照正序

df.sort_values(by='B')#按数值进行排序 ‘B’代表按B的那一列数值排序
```



#### 重整

#### 分组

#### 标准化

#### 转置

```python
df.T#转置数据
```

#### 字符串方法

```python
s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
s.str.lower()#字符串转为小写
```



### 缺失值处理

Pandas主要使用值np.nan来表示缺失的数据。 默认情况下，它不包含在计算中。

```python
#重建索引允许你更改/添加/删除指定轴上的索引。这个操作会返回一个副本(不会更改原来的对象)。
df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])
#重建索引，创建带有缺失值的数据
df1.loc[dates[0]:dates[1], 'E'] = 1
```

#### 剔除缺失数据

```python
df1.dropna(how='any')#删除任何带有缺失值的行
```

#### 填充缺失数据

```python
df1.fillna(value=5)#填充缺失值 重新赋值5
```

#### 获取缺失值掩码

```python
pd.isna(df1)#获取值为nan的掩码
```

### 数据统计

#### 平均值

```python
df.mean()#对一列数据取平均
df.mean(1)#对一行数据取平均
```



#### 最大值、最小值

#### 绘图预处理

##### 直方图化

```python
s = pd.Series(np.random.randint(0, 7, size=6))
s_v = s.value_counts()#s_v为numpy类型的
s_v.plot(kind='bar')#value_counts()对每列数据出现的次数进行统计
```

### 数据输入输出

```python
df.to_csv('foo.csv')#写CSV文件
pd.read_csv('foo.csv')#读CSV文件
df.to_hdf('foo.h5', 'df')#写HDF5文件
pd.read_hdf('foo.h5', 'df')#读HDF5文件
df.to_excel('foo.xlsx', sheet_name='Sheet1')#写Excel文件
pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])#读Excel文件

```

