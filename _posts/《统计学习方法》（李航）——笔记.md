# 《统计学习方法》（李航）——笔记

### 1.1 统计学习

#### 1.1.1 统计学习特点

统计学习（statistical learning）是关于计算机 基于数据构建概率统计模型，并用模型进行预测与分析的学科。统计学习也称为统计机器学习。

统计学习的特点：

* 统计学习以计算机和网络为平台，是建立在计算机与网络上的
* 以数据为研究对象，是数据驱动的学科
* 目的是对数据进行预测和分析
* 以方法为中心

> 赫尔蒙特.西蒙对学习下的定义是：如果**一个系统能够通过执行某个过程改进它的性能**，这就是学习。

#### 1.1.2统计学习的对象

统计学习的对象是数据。

统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。

#### 1.1.3 统计学习的目的

统计学习的总目的是考虑学习什么样的模型和如何学习模型，以使得模型能对数据进行准确的预测和分析，同时也要尽可能的提高效率。

#### 1.1.4 统计学习方法

统计学习可以简单分为监督学习、无监督学习和强化学习。

统计学习的步骤大概分为以下几步：

1. 得到一个有限的训练数据集合
2. 模型——确定包含所有可能的模型的假设空间，即学习模型的集合
3. 策略——确定模型的选择准则
4. 算法——实现求解最优模型的算法
5. 通过学习选择最优模型
6. 利用最优模型对新数据进行分析和预测

#### 1.1.5 统计学习的研究

一般分为以下三方面：

* 统计学习方法的研究：旨在开发新的学习方法
* 统计学习理论的研究：旨在探求统计学习方法的有效性及效率，以及基本理论问题
* 统计学习应用的研究：旨在将统计学习方法应用到实际问题以解决实际问题

#### 1.1.6 统计学习的重要性

* 处理海量数据
* 计算机智能化的有效手段
* 计算机科学发展的重要组成部分

### 1.2 统计学习分类

#### 1.2.1 基本分类  

**监督学习**：输入到输出的映射    

* 输入空间：输入所有可能取值    

* 输出空间：输出所有可能取值    

* 特征空间：所有特征向量存在的空间    

* 假设空间：输入空间但输出空间映射的集合，也即所有可能的模型    

* 联合概率分布：监督学习假设输入与输出的随机变量遵循联合概率分布，这也是统计学习的基本假设  

**非监督学习**：学习数据中统计规律或潜在结构  

**强化学习**：指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题  

**半监督学习与主动学习**    

* 半监督学习：利用标注数据和未标注数据学习预测模型的机器学习问题    

* 主动学习：机器不断给出实例让教师标注，然后利用标注数据学习预测模型的问题 按模型  概率模型与非概率模型  线性模型与非线性模型  参数化模型与非参数化模型 

#### 1.2.2 按算法  

**在线学习**

每接收一个样本，进行学习，然后训练模型  

**离线学习（批量学习）**

一次接受所有数据，训练模型，然后进行预测 

#### 1.2.3 按技巧  

##### 贝叶斯学习    

* 概念：又称贝叶斯推理，是统计学，机器学习的重要方法    

* 原理：在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据模型下模型的条件概率，即后验概率    

这里涉及到贝叶斯估计与最大似然估计的不同，以及先验和后验的知识，参照[链接](https://www.cnblogs.com/jiangxinyang/p/9378535.html)        

[贝叶斯推断与beta分布](https://www.matongxue.com/madocs/910.html)    

[如何通俗理解 beta 分布](https://blog.csdn.net/taoqick/article/details/83038995)        

[beta分布百科](https://baike.baidu.com/item/%E8%B4%9D%E5%A1%94%E5%88%86%E5%B8%83/8994021?fr=aladdin)

##### 核方法

[核方法、核技巧、核函数](https://zhuanlan.zhihu.com/p/61794781)

[SVM专栏](https://zhuanlan.zhihu.com/p/61123737)

[通俗理解核方法(kernel function)](https://blog.csdn.net/u014662865/article/details/80970470)

使用核函数表示和学习非线性模型的机器学习方法，可用于监督学习和非监督学习

### 1.3 统计学习三要素 

#### 1.3.1 模型  

条件概率模型  

决策函数 

#### 1.3.2 策略  

定义：按照什么样的准则从假设空间中学习或选择最优模型  

##### 损失函数和风险函数

[损失函数、代价函数与目标函数](https://blog.csdn.net/lyl771857509/article/details/79428475)        

损失函数：表示估计值与实际值差值的度量        

风险函数        

* 经验风险        

* 结构风险：为防止模型过于复杂导致过拟合而添加的正则项  

经验风险最小化和结构风险最小化 

#### 1.3.3 算法

定义：学习模型的具体计算方法 根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么方法求解最优模型

### 1.4 模型评估与模型选择 

训练误差与测试误差  

* 训练误差：只判断指定问题是不是一个容易学习的问题  

* 测试误差：衡量模型的泛化能力 过拟合与模型选择  

为什么模型拟合：当假设空间含有不同复杂度的模型时，就要面临模型选择的问题  

过拟合：模型对训练数据表现良好而对测试数据或者未知数据拟合很差的现象

### 1.5 防止过拟合 

##### 正则化  

定义：正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项或罚项  

规律：模型越复杂，正则化值越大  

目的：令学得的模型即泛化能力强同时又具有最简单的结构  

正则化符合奥卡姆剃刀原理 

##### 交叉验证  

目的：在训练数据不足的情况下提高模型的学习效果  

方法：重复地使用数据，把给定的数据进行切分，将切分的数据集组合为训练集和测试集，在此基础上反复训练  分类    

* 简单交叉验证    

* S交叉验证    

* 留一交叉验证

### 1.6 泛化能力 

泛化误差：模型预测值与实际值之间的误差 泛化误差上界：泛化误差的概率上界

### 1.7 模型类型 

生成模型：数据学习联合概率密度，然后求出条件概率密度 

判别模型：由数据直接学习判别函数或条件概率分布

### 1.8 监督学习应用 

##### 分类问题  

定义：从数据中学习一个分类模型或分类决策函数，称分类器  

评价指标:    

* 精确率    
* 召回率 

##### 标注问题  

定义：输入一个观测序列，输出一个标记序列或状态序列 回归问题 

定义：预测输入变量与输出变量的关系



## 奇异值分解

[奇异值分解在图像压缩中的应用](https://www.cnblogs.com/endlesscoding/p/10033527.html#3609462498)